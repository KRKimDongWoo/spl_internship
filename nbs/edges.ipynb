{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import Tensor, randint\n",
    "import torch.nn as nn\n",
    "from ..layer import Flatten\n",
    "from ..function import ceil_power_of_two\n",
    "\n",
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, randint\n",
    "import torch.nn as nn\n",
    "from include.layer import Flatten\n",
    "from include.function import ceil_power_of_two\n",
    "\n",
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "NOISE_RATIO = 1e-4\n",
    "COPY_RATIO = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Edge:\n",
    "    def __init__(self, src, dest, layer=None, identical=False):\n",
    "        self.src = src\n",
    "        self.dest = dest\n",
    "        self.identical = identical\n",
    "        if not identical:\n",
    "            self.layer = layer\n",
    "    \n",
    "    def as_layer(self):\n",
    "        return self.layer\n",
    "    \n",
    "    def updated_src(self, in_shape, out_shape, expanded=[]):\n",
    "        return out_shape, expanded\n",
    "    \n",
    "    def updated_dest(self, in_shape, out_shape, expanded=[]):\n",
    "        return in_shape, expanded\n",
    "    \n",
    "    def calculate_output(self, in_shape):\n",
    "        return in_shape\n",
    "    \n",
    "    def verify_output(self, in_shape, out_shape):\n",
    "        expected_output = self.calculate_output(in_shape)\n",
    "        if expected_output == None: return False\n",
    "        if len(expected_output) != len(out_shape): return False\n",
    "        for e, o in zip(expected_output, out_shape):\n",
    "            if e > 0 and o > 0:\n",
    "                if e != o: return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_noise(weight):\n",
    "    noise_range = np.ptp(weight.flatten()) * NOISE_RATIO\n",
    "    noise = np.random.uniform(-noise_range/2.0, noise_range/2.0, weight.shape)\n",
    "    return np.add(weight, noise).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FlattenEdge(Edge):\n",
    "    def __init__(self, src, dest):\n",
    "        super(FlattenEdge, self).__init__(src, dest, layer=Flatten(), identical=False)\n",
    "    \n",
    "    def updated_src(self, in_shape, out_shape, expanded=[]):\n",
    "        out_shape = self.calculate_output(in_shape)\n",
    "        feature_size = out_shape[0] // in_shape[0]\n",
    "        \n",
    "        new_expanded = []\n",
    "        for o, c in expanded:\n",
    "            if o < 0:\n",
    "                origin = (-1,) * feature_size\n",
    "            else:\n",
    "                origin = range(o*feature_size, (o+1)*feature_size)\n",
    "            copied = range(c*feature_size, (c+1)*feature_size)\n",
    "            new_expanded.extend((o, c) for o, c in zip(origin, copied))\n",
    "            \n",
    "        return out_shape, new_expanded\n",
    "    \n",
    "    def calculate_output(self, in_shape):\n",
    "        total = 1\n",
    "        nf = in_shape[0]\n",
    "        for i in in_shape:\n",
    "            total = total * i\n",
    "        out_shape = (total,)\n",
    "        return out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchNormEdge(Edge):\n",
    "    \n",
    "    def __init__(self, src, dest, num_features):\n",
    "        self.args = {\n",
    "            'num_features': num_features,\n",
    "        }\n",
    "        super(BatchNormEdge, self).__init__(src, \n",
    "                                          dest, \n",
    "                                          layer=nn.BatchNorm2d(**self.args), \n",
    "                                          identical=False)\n",
    "    def set_zeros(self):\n",
    "        nn.init.constant_(self.layer.weight, 0)\n",
    "        \n",
    "    def set_identical(self):\n",
    "        self.layer.reset_running_stats()\n",
    "        self.layer.reset_parameters()\n",
    "        nn.init.constant_(self.layer.bias, 0)\n",
    "        nn.init.uniform_(self.layer.weight, a=1.0-NOISE_RATIO, b=1.0+NOISE_RATIO)\n",
    "        \n",
    "    def updated_src(self, in_shape, out_shape, expanded=[]):\n",
    "        \n",
    "        nf = in_shape[0]\n",
    "        extended_params = {\n",
    "            'weight': Tensor(nf),\n",
    "            'bias': Tensor(nf)\n",
    "        }\n",
    "        \n",
    "        # Get original parameters.\n",
    "        params = dict((name, value.data) for (name, value) in self.layer.named_parameters())\n",
    "        \n",
    "        # Expand original parameters\n",
    "        for key in params.keys():\n",
    "            extended_params[key][:len(params[key])] = params[key]\n",
    "            for o, c in expanded:\n",
    "                if o < 0:\n",
    "                    extended_params[key][c].fill_(0.)\n",
    "                else:\n",
    "                    extended_params[key][c] = extended_params[key][o]\n",
    "            extended_params[key] = add_noise(extended_params[key])\n",
    "        \n",
    "        # Update argument\n",
    "        self.args['num_features'] = nf\n",
    "        \n",
    "        # Update the layer\n",
    "        new_layer = nn.BatchNorm2d(**self.args)\n",
    "        new_layer.weight.data = extended_params['weight']\n",
    "        new_layer.bias.data = extended_params['bias']\n",
    "        self.layer = new_layer\n",
    "        \n",
    "        # Generate new output shape\n",
    "        out_shape = in_shape\n",
    "        return out_shape, expanded\n",
    "    \n",
    "    def updated_dest(self, in_shape, out_shape, expanded=[]):\n",
    "        \n",
    "        nf = out_shape[0]\n",
    "        extended_params = {\n",
    "            'weight': Tensor(nf),\n",
    "            'bias': Tensor(nf)\n",
    "        }\n",
    "        \n",
    "         # Get original parameters.\n",
    "        params = dict((name, value.data) for (name, value) in self.layer.named_parameters())\n",
    "        \n",
    "        # Expand original parameters\n",
    "        for key in params.keys():\n",
    "            extended_params[key][:len(params[key])] = params[key]\n",
    "            for o, c in expanded:\n",
    "                if o < 0:\n",
    "                    extended_params[key][c].fill_(0.)\n",
    "                else:\n",
    "                    extended_params[key][c] = extended_params[key][o]\n",
    "            extended_params[key] = add_noise(extended_params[key])\n",
    "        \n",
    "        # Update argument\n",
    "        self.args['num_features'] = nf\n",
    "        \n",
    "        # Update the layer\n",
    "        new_layer = nn.BatchNorm2d(**self.args)\n",
    "        new_layer.weight.data = extended_params['weight']\n",
    "        new_layer.bias.data = extended_params['bias']\n",
    "        self.layer = new_layer\n",
    "        \n",
    "        # Generate new input shape\n",
    "        in_shape = out_shape\n",
    "        return in_shape, expanded\n",
    "    \n",
    "    def calculate_output(self, in_shape):\n",
    "        if in_shape[0] != self.args['num_features']: return None\n",
    "        else: return in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReluEdge(Edge):\n",
    "    def __init__(self, src, dest):\n",
    "        self.args = {\n",
    "        }\n",
    "        super(ReluEdge, self).__init__(src,                                       \n",
    "                                       dest, \n",
    "                                       layer=nn.ReLU(), \n",
    "                                       identical=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PoolingEdge(Edge):\n",
    "    def _get_layer(self):\n",
    "        pass\n",
    "    \n",
    "    def __init__(self, src, dest, kernel_size):\n",
    "        kernel_size = (kernel_size,) * 2 if isinstance(kernel_size, int) else kernel_size\n",
    "        stride = kernel_size\n",
    "        padding = (0,) * 2\n",
    "        \n",
    "        self.args = {\n",
    "            'kernel_size': kernel_size,\n",
    "            'stride': stride,\n",
    "            'padding': padding,\n",
    "            'ceil_mode': True\n",
    "        }\n",
    "        \n",
    "        super(PoolingEdge, self).__init__(src, \n",
    "                                          dest, \n",
    "                                          layer=self._get_layer()(**self.args), \n",
    "                                          identical=False)\n",
    "    \n",
    "    def updated_src(self, in_shape, out_shape, expanded=[]):\n",
    "        out_shape = self.calculate_output(in_shape)\n",
    "\n",
    "        return out_shape, expanded\n",
    "    \n",
    "    def updated_dest(self, in_shape, out_shape, expanded=[]):\n",
    "        exp_shape = self.calculate_output(in_shape)\n",
    "        if(out_shape[1:] != exp_shape[1:]):\n",
    "            stride = tuple(ceil_power_of_two(i/o) for i, o in zip(in_shape[1:], out_shape[1:]))\n",
    "            kernel_size = stride\n",
    "            padding = (0,) * 2\n",
    "            self.args['kernel_size'] = kernel_size\n",
    "            self.args['padding'] = padding\n",
    "            self.args['stride'] = stride\n",
    "            \n",
    "            self.layer = self._get_layer()(**self.args)\n",
    "        \n",
    "        in_shape = (out_shape[0],) + in_shape[1:]\n",
    "            \n",
    "        return in_shape, expanded\n",
    "        \n",
    "    def calculate_output(self, in_shape):\n",
    "        nf = (in_shape[0],)\n",
    "        attr = zip(in_shape[1:],\n",
    "                   self.args['kernel_size'],\n",
    "                   self.args['stride'],\n",
    "                   self.args['padding'])\n",
    "        ch = tuple([ceil((x + 2 * pd - ks) / st) + 1 for x, ks, st, pd in attr])\n",
    "        out_shape = nf + ch\n",
    "        return out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MaxPoolingEdge(PoolingEdge):\n",
    "    def _get_layer(self):\n",
    "        return nn.MaxPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgPoolingEdge(PoolingEdge):\n",
    "    def _get_layer(self):\n",
    "        return nn.AvgPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdaptivePoolingEdge(Edge):\n",
    "    def __init__(self, src, dest, output_size):\n",
    "        pass\n",
    "    \n",
    "    def _set_args(self, output_size):\n",
    "        self.args={\n",
    "            'output_size': output_size\n",
    "        }\n",
    "    \n",
    "    def updated_src(self, in_shape, expanded=[]):\n",
    "        return self.args['output_size'], expanded\n",
    "    \n",
    "    def calculate_output(self, in_shape):\n",
    "        return self.args['output_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdaptiveMaxPoolingEdge(AdaptivePoolingEdge):\n",
    "    def __init__(self, src, dest, output_size):\n",
    "        self._set_args(output_size)\n",
    "        super(AdaptivePoolingEdge, self).__init__(src,\n",
    "                                                  dest,\n",
    "                                                  layer=nn.AdaptiveMaxPool2d(**self.args),\n",
    "                                                  identical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdaptiveAvgPoolingEdge(AdaptivePoolingEdge):\n",
    "    def __init__(self, src, dest, output_size):\n",
    "        self._set_args(output_size)\n",
    "        super(AdaptivePoolingEdge, self).__init__(src,\n",
    "                                                  dest,\n",
    "                                                  layer=nn.AdaptiveAvgPool2d(**self.args),\n",
    "                                                  identical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LinearEdge(Edge):\n",
    "    def __init__(self, src, dest, in_features, out_features, bias=True):\n",
    "        self.args = {\n",
    "            'in_features': in_features,\n",
    "            'out_features': out_features,\n",
    "            'bias': bias\n",
    "        }\n",
    "        super(LinearEdge, self).__init__(src,\n",
    "                                         dest,\n",
    "                                         layer=nn.Linear(**self.args),\n",
    "                                         identical=False)\n",
    "    \n",
    "    def set_identical(self):\n",
    "        if self.args['in_features'] != self.args['out_features']:\n",
    "            raise Exception('Cannot set identical weight')\n",
    "        nn.init.constant_(self.layer.weight.data, 0.)\n",
    "        nn.init.constant_(self.layer.bias.data, 0.)\n",
    "        \n",
    "        ni = self.args['in_features']\n",
    "        for i in range(ni):\n",
    "            self.layer.weight.data[i,i] = 1\n",
    "            \n",
    "        self.layer.weight.data = add_noise(self.layer.weight.data)\n",
    "    \n",
    "    def updated_src(self, in_shape, out_shape, expanded=[]):\n",
    "        ni = in_shape[0]\n",
    "        \n",
    "        # Get original parameters\n",
    "        params = dict((name, value.data) for (name, value) in self.layer.named_parameters())\n",
    "        \n",
    "        # Expand original parameters\n",
    "        expanded_weight = Tensor(self.args['out_features'], ni)\n",
    "        expanded_weight[:,:self.args['in_features']] = params['weight']\n",
    "        for o, c in expanded:\n",
    "            if o < 0:\n",
    "                expanded_weight[:,c].fill_(0.)\n",
    "            else:\n",
    "                expanded_weight[:,c] = params['weight'][:,o]\n",
    "        expanded_weight = add_noise(expanded_weight)\n",
    "        \n",
    "        # Update the args\n",
    "        self.args['in_features'] = ni\n",
    "        \n",
    "        # Update the layer\n",
    "        new_layer = nn.Linear(**self.args)\n",
    "        new_layer.weight.data = expanded_weight\n",
    "        new_layer.bias.data = params['bias']\n",
    "        self.layer = new_layer\n",
    "        \n",
    "        # Generate new output shape\n",
    "        out_shape = self.calculate_output(in_shape)\n",
    "        return out_shape, []\n",
    "    \n",
    "    def updated_dest(self, out_shape):\n",
    "        raise Excpetion('unimplemented')\n",
    "    \n",
    "    def calculate_output(self, in_shape):\n",
    "        if in_shape[0] != self.args['in_features']: return None\n",
    "        return (self.args['out_features'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvEdge(Edge):\n",
    "    def __init__(self, src, dest, \n",
    "                 in_channels, out_channels, kernel_size, stride=1, bias=True):\n",
    "        kernel_size = (kernel_size,) * 2 if isinstance(kernel_size, int) else kernel_size\n",
    "        padding = tuple(ks//2 for ks in kernel_size)\n",
    "        stride = (stride,) * 2 if isinstance(stride, int) else stride\n",
    "        \n",
    "        self.args = {\n",
    "            'in_channels': in_channels,\n",
    "            'out_channels': out_channels,\n",
    "            'kernel_size': kernel_size,\n",
    "            'stride': stride,\n",
    "            'padding': padding,\n",
    "            'bias': bias\n",
    "        }\n",
    "        super(ConvEdge, self).__init__(src, \n",
    "                                       dest,\n",
    "                                       layer=nn.Conv2d(**self.args),                                           \n",
    "                                       identical=False)\n",
    "        \n",
    "    def set_identical(self):\n",
    "        if self.args['in_channels'] != self.args['out_channels']:\n",
    "            raise Exception('Cannot set identical weight')\n",
    "        center = tuple(i // 2 for i in self.args['kernel_size'])\n",
    "        nf = self.args['in_channels']\n",
    "        \n",
    "        nn.init.constant_(self.layer.weight, 0.)\n",
    "        if self.args['bias']: nn.init.constant_(self.layer.bias, 0.)\n",
    "        for i in range(nf):\n",
    "            self.layer.weight.data[i,i,center[0],center[1]] = 1.\n",
    "        \n",
    "        self.layer.weight.data = add_noise(self.layer.weight.data)\n",
    "        \n",
    "    def updated_src(self, in_shape, out_shape, expanded=[]):\n",
    "        ni = in_shape[0]\n",
    "        nf = self.args['out_channels']\n",
    "        \n",
    "        # Update the args\n",
    "        self.args['in_channels'] = ni\n",
    "    \n",
    "        # Adjust stride\n",
    "        exp_shape = self.calculate_output(in_shape)\n",
    "        if exp_shape[1:] != out_shape[1:]:\n",
    "            stride = tuple(self._calculate_stride(i, o) for i, o in zip(in_shape[1:], out_shape[1:]))\n",
    "            self.args['stride'] = stride\n",
    "        \n",
    "        # Get original parameters\n",
    "        params = dict((name, value.data) for (name, value) in self.layer.named_parameters())\n",
    "        \n",
    "        # Expand original parameters\n",
    "        expanded_weight = Tensor(nf, ni, *self.args['kernel_size'])\n",
    "        expanded_weight[:, :self.args['in_channels'], ...] = params['weight']\n",
    "        for o, c in expanded:\n",
    "            if o < 0:\n",
    "                expanded_weight[:, c, ...].fill_(0.)\n",
    "            else:\n",
    "                expanded_weight[:, c, ...] = params['weight'][:, o, ...]\n",
    "        expanded_weight = add_noise(expanded_weight)\n",
    "    \n",
    "        # Update the layer\n",
    "        new_layer = nn.Conv2d(**self.args)\n",
    "        new_layer.weight.data = expanded_weight\n",
    "        if self.args['bias']: new_layer.bias.data = params['bias']\n",
    "        self.layer = new_layer\n",
    "        \n",
    "        # Generate new output shape\n",
    "        out_shape = self.calculate_output(in_shape)\n",
    "        return out_shape, []\n",
    "    \n",
    "    def updated_dest(self, in_shape, out_shape, expanded=[]):\n",
    "        ni = self.args['in_channels']\n",
    "        nf = out_shape[0] if out_shape[0] > 0 else self.args['out_channels']\n",
    "        prev_nf = self.args['out_channels']\n",
    "\n",
    "        # Update the args\n",
    "        self.args['out_channels'] = nf\n",
    "        \n",
    "        # Adjust stride\n",
    "        exp_shape = self.calculate_output(in_shape)\n",
    "        if exp_shape[1:] != out_shape[1:]:\n",
    "            stride = tuple(ceil_power_of_two(i, o) for i, o in zip(in_shape[1:], out_shape[1:]))\n",
    "            self.args['stride'] = stride\n",
    "        \n",
    "        # Get original parameters\n",
    "        params = dict((name, value.data) for (name, value) in self.layer.named_parameters())\n",
    "        \n",
    "        # Expand original parameters\n",
    "        expanded_params = {}\n",
    "        expanded_params['weight'] = Tensor(nf, ni, *self.args['kernel_size'])\n",
    "        if self.args['bias']: expanded_params['bias'] = Tensor(nf)\n",
    "        \n",
    "        rand = randint(prev_nf, (nf - prev_nf,))\n",
    "        for key in params.keys():\n",
    "            expanded_params[key][:prev_nf, ...] = params[key]\n",
    "        \n",
    "            for o, c in expanded:\n",
    "                if o < 0:\n",
    "                    expanded_params[key][c, ...].fill_(0.)\n",
    "                else:\n",
    "                    expanded_params[key][c, ...] = expanded_params[key][o, ...] * COPY_RATIO\n",
    "                    expanded_params[key][o, ...] = expanded_params[key][o, ...] * (1 - COPY_RATIO)\n",
    "            add_noise(expanded_params[key])\n",
    "        \n",
    "        # Update the layer\n",
    "        new_layer = nn.Conv2d(**self.args)\n",
    "        new_layer.weight.data = expanded_params['weight']\n",
    "        if self.args['bias']: new_layer.bias.data = expanded_params['bias']\n",
    "        self.layer = new_layer\n",
    "        \n",
    "        # Generate new input shape\n",
    "        in_shape = (ni,) + in_shape[1:]\n",
    "        return in_shape, []\n",
    "    \n",
    "    def calculate_output(self, in_shape):\n",
    "        if(in_shape[0] != self.args['in_channels']): return None\n",
    "        nf = self.args['out_channels']\n",
    "        attr = zip(in_shape[1:],\n",
    "                   self.args['kernel_size'],\n",
    "                   self.args['stride'],\n",
    "                   self.args['padding'])\n",
    "        ch = tuple([(x + 2 * pd - ks) // st + 1 for x, ks, st, pd in attr])\n",
    "        out_shape = (nf,) + ch\n",
    "        return out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IdenticalEdge(Edge):\n",
    "    def __init__(self, src, dest):\n",
    "        super(IdenticalEdge, self).__init__(src,\n",
    "                                            dest,\n",
    "                                            layer=None,\n",
    "                                            identical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted edges.ipynb to exp/nb_edges.py\r\n"
     ]
    }
   ],
   "source": [
    "!python nb2py.py edges.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = FlattenEdge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048,), [])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.updated_src((1, 32, 64), (256)) # expected: 1*32*64=2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([0.4726, 0.2227, 0.4838, 0.9731], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0.], requires_grad=True)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = BatchNormEdge(1, 2, num_features=4)\n",
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 16, 16), [(0, 4), (0, 5), (1, 6), (2, 7)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.updated_src((8, 16, 16), (16, 16, 16), expanded=[(0, 4), (0, 5), (1, 6), (2, 7)])\n",
    "# expected: ((8, 16, 16), [(0, 4), (0, 5), (1, 6), (2, 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([0.4726, 0.2227, 0.4838, 0.9731, 0.4725, 0.4726, 0.2227, 0.4838],\n",
       "        requires_grad=True), 'bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([0.8387, 0.7745, 0.4892, 0.8002], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0.], requires_grad=True)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = BatchNormEdge(1, 2, num_features=4)\n",
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 16, 16), [(0, 4), (0, 5), (1, 6), (2, 7)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.updated_dest((4, 16, 16), (8, 16, 16), expanded=[(0, 4), (0, 5), (1, 6), (2, 7)])\n",
    "# expected: ((8, 16, 16), [(0, 4), (0, 5), (1, 6), (2, 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([0.8388, 0.7745, 0.4893, 0.8002, 0.8388, 0.8387, 0.7745, 0.4892],\n",
       "        requires_grad=True), 'bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ReluEdge(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 32, 32), [])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.updated_src((4, 32, 32), (8, 32, 32)) # expected: ((4, 32, 32), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 32, 32), [])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.updated_dest((4, 32, 32), (8, 32, 32)) # expected: ((8, 32, 32), [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[[[ 0.1053, -0.1115,  0.2315],\n",
       "           [ 0.2143, -0.0862, -0.0453],\n",
       "           [-0.1009,  0.2997,  0.1473]]],\n",
       " \n",
       " \n",
       "         [[[-0.2723, -0.1759, -0.1692],\n",
       "           [-0.1313,  0.2518, -0.0463],\n",
       "           [-0.0440, -0.3183,  0.0468]]]], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([0.0240, 0.0457], requires_grad=True)}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = ConvEdge(1, 2, in_channels=1, out_channels=2, kernel_size=3)\n",
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 32, 32), [])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.updated_src((3, 64, 64), (2, 32, 32), expanded=[(0, 1), (0, 2)])\n",
    "# expected: ((2, 32, 32), [(0, 1), (0, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[[[ 0.1053, -0.1115,  0.2315],\n",
       "           [ 0.2143, -0.0862, -0.0453],\n",
       "           [-0.1008,  0.2997,  0.1473]],\n",
       " \n",
       "          [[ 0.1053, -0.1115,  0.2316],\n",
       "           [ 0.2143, -0.0862, -0.0453],\n",
       "           [-0.1009,  0.2997,  0.1473]],\n",
       " \n",
       "          [[ 0.1053, -0.1115,  0.2315],\n",
       "           [ 0.2143, -0.0862, -0.0453],\n",
       "           [-0.1009,  0.2997,  0.1473]]],\n",
       " \n",
       " \n",
       "         [[[-0.2722, -0.1759, -0.1692],\n",
       "           [-0.1313,  0.2517, -0.0464],\n",
       "           [-0.0441, -0.3183,  0.0468]],\n",
       " \n",
       "          [[-0.2723, -0.1759, -0.1692],\n",
       "           [-0.1313,  0.2517, -0.0463],\n",
       "           [-0.0440, -0.3183,  0.0468]],\n",
       " \n",
       "          [[-0.2723, -0.1759, -0.1692],\n",
       "           [-0.1312,  0.2517, -0.0464],\n",
       "           [-0.0440, -0.3183,  0.0468]]]], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([0.0240, 0.0457], requires_grad=True)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[[[-0.1795, -0.1808, -0.0885],\n",
       "           [ 0.1792, -0.0700,  0.0561],\n",
       "           [ 0.2513,  0.2168,  0.2726]]],\n",
       " \n",
       " \n",
       "         [[[-0.2957, -0.0678, -0.0680],\n",
       "           [ 0.2473,  0.2039, -0.2607],\n",
       "           [ 0.1112, -0.0219,  0.2473]]]], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([0.1575, 0.1056], requires_grad=True)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = ConvEdge(1, 2, in_channels=1, out_channels=2, kernel_size=3)\n",
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 32, 32), [])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.updated_dest((1, 32, 32), (3, 32, 32), expanded=[(0, 1), (0, 2)])\n",
    "# expected: ((1, 32, 32), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[[[-0.1178, -0.1186, -0.0581],\n",
       "           [ 0.1176, -0.0459,  0.0368],\n",
       "           [ 0.1649,  0.1423,  0.1788]]],\n",
       " \n",
       " \n",
       "         [[[-0.0145, -0.0146, -0.0072],\n",
       "           [ 0.0145, -0.0057,  0.0045],\n",
       "           [ 0.0204,  0.0176,  0.0221]]],\n",
       " \n",
       " \n",
       "         [[[-0.0131, -0.0132, -0.0065],\n",
       "           [ 0.0131, -0.0051,  0.0041],\n",
       "           [ 0.0183,  0.0158,  0.0199]]]], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([0.1033, 0.0128, 0.0115], requires_grad=True)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[ 0.2308, -0.0498, -0.1879,  0.2135, -0.3400,  0.3394,  0.2523,  0.1279],\n",
       "         [-0.2935, -0.0145, -0.3510, -0.1728,  0.1548,  0.0996,  0.1312,  0.2018],\n",
       "         [ 0.1953, -0.0719, -0.0529,  0.0881, -0.1222,  0.2442, -0.1137, -0.0499],\n",
       "         [-0.2452,  0.3248, -0.2244,  0.0757, -0.2155, -0.1099, -0.2374,  0.0080]],\n",
       "        requires_grad=True), 'bias': Parameter containing:\n",
       " tensor([-0.0986,  0.0423, -0.3287,  0.2617], requires_grad=True)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = LinearEdge(1, 2, in_features=8, out_features=4)\n",
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4,), [])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.updated_src((12,), (4,), expanded=[(0, 8), (1, 9), (2, 10), (3, 11)])\n",
    "#expected output: ((4,), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[-3.3364e-01,  2.1472e-02, -8.7307e-02, -1.9922e-01, -1.4765e-01,\n",
       "          -2.5906e-04,  2.6748e-01,  2.1161e-01, -3.3358e-01,  2.1466e-02,\n",
       "          -8.7265e-02, -1.9922e-01],\n",
       "         [-2.6385e-01, -2.4632e-01, -1.8650e-01,  3.0797e-01,  1.4379e-01,\n",
       "          -2.5802e-02,  1.2031e-02,  2.5626e-01, -2.6388e-01, -2.4634e-01,\n",
       "          -1.8650e-01,  3.0802e-01],\n",
       "         [-3.2306e-01, -3.2754e-01,  1.6925e-01, -2.9471e-01, -2.1961e-01,\n",
       "           3.2708e-01,  1.8376e-01,  2.1620e-01, -3.2307e-01, -3.2758e-01,\n",
       "           1.6929e-01, -2.9472e-01],\n",
       "         [ 2.1766e-01,  2.3562e-02,  1.3202e-01, -3.4360e-01,  2.4459e-01,\n",
       "          -3.4941e-01, -2.6102e-01,  1.4828e-01,  2.1764e-01,  2.3578e-02,\n",
       "           1.3202e-01, -3.4361e-01]], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([-0.1665, -0.2551, -0.3307, -0.0511], requires_grad=True)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(e.layer.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 3, 5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (2, 5, *x); x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
